#!/usr/bin/env python3
import os
import glob
import pandas as pd

# ğŸ“Œ DÃ©finition des chemins basÃ©s sur la structure du projet
script_dir = os.path.dirname(os.path.realpath(__file__))            # .../ESKINAZI_Etienne_NAJI_Ramzi_projet_BGD_airflow/extract_data_scripts
project_root = os.path.abspath(os.path.join(script_dir, ".."))      # .../ESKINAZI_Etienne_NAJI_Ramzi_projet_BGD_airflow

# ğŸ“Œ Lire le chemin des rÃ©sultats depuis results_path.txt
with open(os.path.join(project_root, "results_path.txt"), "r") as f:
    data_root = f.read().strip()

# ğŸ“Œ DÃ©finition des dossiers et fichiers
histo_file = os.path.join(data_root, "raw_data", "yahoo_finance", "histo_data", "sp500_histo_close_prices.csv")
realtime_data_dir = os.path.join(data_root, "raw_data", "yahoo_finance", "realtime_data")
output_file = os.path.join(data_root, "formatted_data", "concatenated_files", "sp500_concatenated.csv")

# ğŸ“Œ Fonction pour charger les donnÃ©es historiques du S&P 500
def load_historical_data(file_path):
    df = pd.read_csv(file_path)
    df = df.rename(columns={'close': 'price'})
    df["date"] = pd.to_datetime(df["date"]).dt.strftime('%Y-%m-%d')  # Format YYYY-MM-DD
    return df

# ğŸ“Œ Fonction pour charger les fichiers temps rÃ©el du S&P 500
def load_realtime_data(file_path):
    df = pd.read_csv(file_path)
    df = df.rename(columns={'timestamp': 'date'})
    df["date"] = pd.to_datetime(df["date"]).dt.strftime('%Y-%m-%d')  # Format YYYY-MM-DD
    return df

# VÃ©rifier l'existence du fichier historique
if not os.path.exists(histo_file):
    print(f"âŒ Erreur : Fichier historique non trouvÃ© : {histo_file}")
    exit(1)
sp500_histo = load_historical_data(histo_file)

# Obtenir la liste des fichiers realtime triÃ©s par date
realtime_files = glob.glob(os.path.join(realtime_data_dir, "*_sp500_realtime_price.csv"))
if not realtime_files:
    print(f"âŒ Erreur : Aucun fichier realtime trouvÃ© dans : {realtime_data_dir}")
    exit(1)
realtime_files.sort()  # Tri par ordre alphabÃ©tique (qui correspond Ã  l'ordre chronologique)

if os.path.exists(output_file):
    # ğŸ“Œ Charger les donnÃ©es existantes
    existing_data = pd.read_csv(output_file)
    latest_date = existing_data["date"].max()
    
    # ğŸ“Œ Filtrer les fichiers plus rÃ©cents que la derniÃ¨re date enregistrÃ©e
    filtered_files = []
    for f in realtime_files:
        temp_df = load_realtime_data(f)
        if temp_df["date"].max() > latest_date:
            filtered_files.append(f)
    
    realtime_files = filtered_files
    
    if realtime_files:
        # ğŸ“Œ Charger et concatÃ©ner les nouvelles donnÃ©es
        new_data = pd.concat([load_realtime_data(f) for f in realtime_files])
        sp500_final = pd.concat([existing_data, new_data])
    else:
        print("â„¹ï¸ Aucune nouvelle donnÃ©e Ã  ajouter.")
        exit(0)
else:
    # ğŸ“Œ Si le fichier de sortie n'existe pas, concatÃ©ner toutes les donnÃ©es
    realtime_data = pd.concat([load_realtime_data(f) for f in realtime_files])
    sp500_final = pd.concat([sp500_histo, realtime_data])

# ğŸ“Œ Supprimer les doublons et trier par timestamp
sp500_final = sp500_final.drop_duplicates(subset=["date"]).sort_values("date")

# ğŸ“Œ Sauvegarder au format CSV
sp500_final.to_csv(output_file, index=False)
print(f"âœ… DonnÃ©es transformÃ©es et enregistrÃ©es dans {output_file}")
